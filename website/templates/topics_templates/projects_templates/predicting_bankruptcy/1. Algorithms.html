<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>1. Algorithms</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
    <!-- End of mathjax configuration -->
</head>
<div class="cell border-box-sizing code_cell rendered">
    <div class="input">
        <div class="prompt input_prompt">In&nbsp;[1]:</div>
        <div class="inner_cell">
            <div class="input_area">
                <div class=" highlight hl-ipython3">
                    <pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span> <span class="k">as</span> <span class="n">accuracy</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">import</span> <span class="nn">catboost</span> <span class="k">as</span> <span class="nn">cb</span>

<span class="kn">import</span> <span class="nn">h2o</span>
<span class="kn">from</span> <span class="nn">h2o.automl</span> <span class="kn">import</span> <span class="n">H2OAutoML</span>
<span class="kn">from</span> <span class="nn">h2o.estimators.gbm</span> <span class="kn">import</span> <span class="n">H2OGradientBoostingEstimator</span>

<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span><span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.metrics</span> <span class="kn">import</span> <span class="n">Metric</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">np_utils</span>
</pre>
                </div>
            </div>
        </div>
    </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
    <div class="input">
        <div class="prompt input_prompt">In&nbsp;[2]:</div>
        <div class="inner_cell">
            <div class="input_area">
                <div class=" highlight hl-ipython3">
                    <pre><span></span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre>
                </div>
            </div>
        </div>
    </div>
    <div class="output_wrapper">
        <div class="output">
            <div class="output_area">
                <div class="prompt"></div>
                <div class="output_png output_subarea ">
                    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
                        <pre>(150, 4)
(array([0, 1, 2]), array([50, 50, 50], dtype=int64))
</pre>
                    </div>
                </div>
                <div class="jp-OutputArea-child">
                    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
                </div>
            </div>
        </div>
    </div>
    <p> The iris dataset has four characteristics (length and breadth of sepals and petals) and 50 samples of each class (Iris setosa, Iris virginica and Iris versicolor). </p>
    <div class="cell border-box-sizing code_cell rendered">
        <div class="input">
            <div class="prompt input_prompt">In&nbsp;[3]:</div>
            <div class="inner_cell">
                <div class="input_area">
                    <div class=" highlight hl-ipython3">
                        <pre><span></span><span class="k">def</span> <span class="nf">simple_classifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">clf</span><span class="p">):</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">predictions</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">clf</span><span class="p">,</span><span class="n">predictions</span><span class="p">,</span><span class="n">score</span>
</pre>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <p>Because most of the algorithms in our list contain the fit and predict properties, we can write a simple function that takes the initialised classifier, our training and target data, and returns the fitted classifier, predictions, and accuracy score. We're writing a function for this procedure since, while it's easy enough, it'll be performed numerous times if not automated - and thus it may be utilised in a function. </p>
    <div class="cell border-box-sizing code_cell rendered">
        <div class="input">
            <div class="prompt input_prompt">In&nbsp;[4]:</div>
            <div class="inner_cell">
                <div class="input_area">
                    <div class=" highlight hl-ipython3">
                        <pre>
<span></span><span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="p">,</span><span class="n">lr_predictions</span><span class="p">,</span><span class="n">lr_score</span> <span class="o">=</span> <span class="n">simple_classifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">lr</span><span class="p">)</span>

<span></span><span class="n">nb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">nb</span><span class="p">,</span><span class="n">nb_predictions</span><span class="p">,</span><span class="n">nb_score</span> <span class="o">=</span> <span class="n">simple_classifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">nb</span><span class="p">)</span>

</span><span class="n">cart</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;gini&quot;</span><span class="p">)</span>
<span class="n">cart</span><span class="p">,</span><span class="n">cart_predictions</span><span class="p">,</span><span class="n">cart_score</span> <span class="o">=</span> <span class="n">simple_classifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">cart</span><span class="p">)</span>

<span class="n">gbm</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">()</span>
<span class="n">gbm</span><span class="p">,</span><span class="n">gbm_predictions</span><span class="p">,</span><span class="n">gbm_score</span> <span class="o">=</span> <span class="n">simple_classifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">gbm</span><span class="p">)</span>

<span></span><span class="n">xgb_clf</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">xgb_clf</span><span class="p">,</span><span class="n">xgb_predictions</span><span class="p">,</span><span class="n">xgb_score</span> <span class="o">=</span> <span class="n">simple_classifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">xgb_clf</span><span class="p">)</span>

<span class="n">cat</span><span class="o">=</span><span class="n">cb</span><span class="o">.</span><span class="n">CatBoostClassifier</span><span class="p">()</span>
<span class="n">cat</span><span class="p">,</span><span class="n">cat_predictions</span><span class="p">,</span><span class="n">cat_score</span> <span class="o">=</span> <span class="n">simple_classifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">cat</span><span class="p">)</span>

</pre>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
<p> We trained and received predictions from the following classifiers using a simple function:
    <ul>
        <li>Logistic Regression</li>
        <li>Naive Bayes</li>
        <li>Classification and Regression Trees</li>
        <li>Gradient Boosting Machines</li>
        <li>Extreme Gradient Boost </li>
        <li>Categorical Boost </li>
    </ul>
</p>
<p> We must emphasise that this is not the best implementation, neither in terms of how a machine learning process should be run nor of the algorithms themselves. This is only a demonstration of how simple it is to get started with various machine learning methods, and it is not indicative of their performance. </p>
<div class="cell border-box-sizing code_cell rendered">
    <div class="input">
        <div class="prompt input_prompt">In&nbsp;[5]:</div>
        <div class="inner_cell">
            <div class="input_area">
                <div class=" highlight hl-ipython3">
                    <pre><span></span><span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">encoded_Y</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">dummy_y</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">encoded_Y</span><span class="p">,</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dummy_y</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">dnn_accuracy</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">preds</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre>
                </div>
            </div>
        </div>
    </div>
</div>
<p> We needed to perform a little more work on our neural network. To begin, we had to one-hot encode our target by converting a 1x150 vector to a 3x150 array, where the column with the value 1 specifies which class is our target. After that, we are free to construct our Neural Network, which consists of an input layer with four inputs (stems from the form of our dataset), a hidden layer with eight neurons, and our output. We utilised relu as activation functions in the intermediate layers and softmax in the output because we have a multiclass classification problem. </p>
<div class="cell border-box-sizing code_cell rendered">
    <div class="input">
        <div class="prompt input_prompt">In&nbsp;[6]:</div>
        <div class="inner_cell">
            <div class="input_area">
                <div class=" highlight hl-ipython3">
                    <pre><span></span><span class="n">h2o</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
</pre>
                </div>
            </div>
        </div>
    </div>
</div>
<div class="output_wrapper">
    <div class="output">
        <div class="output_area">
            <div class="prompt"></div>
            <div class="output_png output_subarea ">
                <img src='/static/categories_pics/projects/predicting_bankruptcy/1. h2o init.png'>
            </div>
        </div>
    </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
    <div class="input">
        <div class="prompt input_prompt">In&nbsp;[7]:</div>
        <div class="inner_cell">
            <div class="input_area">
                <div class=" highlight hl-ipython3">
                    <pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
<span class="n">hf</span><span class="o">=</span><span class="n">h2o</span><span class="o">.</span><span class="n">H2OFrame</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">H2OAutoML</span><span class="p">(</span><span class="n">max_models</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">hf</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">hf</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">training_frame</span><span class="o">=</span><span class="n">hf</span><span class="p">,</span><span class="n">validation_frame</span><span class="o">=</span><span class="n">hf</span><span class="p">)</span>
</pre>
                </div>
            </div>
        </div>
    </div>
</div>
<div class="output_wrapper">
    <div class="output">
        <div class="output_area">
            <div class="prompt"></div>
            <div class="output_png output_subarea ">
                <img src='/static/categories_pics/projects/predicting_bankruptcy/2.1 h2o training.png'>
                <img src='/static/categories_pics/projects/predicting_bankruptcy/2.2 h2o training.png'>
                <img src='/static/categories_pics/projects/predicting_bankruptcy/2.2 h2o results.png'>
            </div>
        </div>
    </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
    <div class="input">
        <div class="prompt input_prompt">In&nbsp;[8]:</div>
        <div class="inner_cell">
            <div class="input_area">
                <div class=" highlight hl-ipython3">
                    <pre><span></span><span class="n">lb</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">leaderboard</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lb</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="n">y_pred</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">leader</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">hf</span><span class="p">)</span>
<span class="n">h2o_accuracy</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">as_data_frame</span><span class="p">(),</span><span class="mi">0</span><span class="p">),</span><span class="n">y</span><span class="p">)</span>
</pre>
                </div>
            </div>
        </div>
    </div>
</div>
<div class="output_wrapper">
    <div class="output">
        <div class="output_area">
            <div class="prompt"></div>
            <div class="output_png output_subarea ">
                <img src='/static/categories_pics/projects/predicting_bankruptcy/3.h2o results.png'>
            </div>
        </div>
    </div>
</div>
<p> H2O now has numerous outputs. Not all of them are useful, especially for our goal here, but I chose to keep them in to avoid confusing folks who haven't used it before and want to try it out. It also has limited support for multiclass classification issues, which is unfortunate, but we can work around this by utilising the rounding method. </p>
<div class="cell border-box-sizing code_cell rendered">
    <div class="input">
        <div class="prompt input_prompt">In&nbsp;[9]:</div>
        <div class="inner_cell">
            <div class="input_area">
                <div class=" highlight hl-ipython3">
                    <pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Logistic Regression: &#39;</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">lr_score</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Gaussian Naive Bayes: &#39;</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">nb_score</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CART: &#39;</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">cart_score</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;GBM: &#39;</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">gbm_score</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;XGB: &#39;</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">xgb_score</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CatBoost: &#39;</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">cat_score</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;DNN: &#39;</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">dnn_accuracy</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;H2O AutoML&#39;</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">h2o_accuracy</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</pre>
                </div>
            </div>
        </div>
    </div>
</div>
<div class="output_wrapper">
    <div class="output">
        <div class="output_area">
            <div class="prompt"></div>
            <div class="output_png output_subarea ">
                <pre>Logistic Regression:  0.96
Gaussian Naive Bayes:  0.96
CART:  1.0
GBM:  1.0
XGB:  1.0
CatBoost:  1.0
DNN:  0.753
H2O AutoML 1.0
</pre>
            </div>
        </div>
    </div>
</div>
<p>
    As can be seen, most algorithms ran well in this dataset. We've already stated that this does not reflect their overall performance. All of the methods work perfectly or almost perfectly, with the exception of the DNN, which was trained using the whole dataset and is hence overfitted. DNN, on the other hand, uses the hyperparameter batch size to combat this in its implementation. This means that during training, 10 samples are loaded and utilised for training each time, until the entire dataset is traversed once - completing one epoch. While we still view the entire dataset, we see it in sections, coming closer to the ideal answer with each batch's information. This kind of training is highly significant and, in fact, superior, but we shall go into more detail in subsequent posts.
</p>
<p> This brings us to the end of this post. Have fun exploring! </p>
</body>

</html>